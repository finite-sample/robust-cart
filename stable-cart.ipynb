{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801acf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Dataset        Model  OOS Accuracy\n",
      "       Low Noise  Robust CART      0.770000\n",
      "       Low Noise Sklearn CART      0.756667\n",
      "  Moderate Noise  Robust CART      0.753333\n",
      "  Moderate Noise Sklearn CART      0.776667\n",
      "     Heavy Noise  Robust CART      0.816667\n",
      "     Heavy Noise Sklearn CART      0.776667\n",
      "Very Heavy Noise  Robust CART      0.713333\n",
      "Very Heavy Noise Sklearn CART      0.700000\n",
      "   Breast Cancer  Robust CART      0.918129\n",
      "   Breast Cancer Sklearn CART      0.900585\n",
      "            Wine  Robust CART      0.962963\n",
      "            Wine Sklearn CART      0.981481\n",
      "          Digits  Robust CART      0.755556\n",
      "          Digits Sklearn CART      0.679630\n"
     ]
    }
   ],
   "source": [
    "# robust_cart.py\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.base import clone\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification, load_breast_cancer, load_wine, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "class RobustCART:\n",
    "    def __init__(self, base_estimator=None, n_subsamples=100, max_depth=5):\n",
    "        self.base_estimator = base_estimator or DecisionTreeClassifier(max_depth=1)\n",
    "        self.n_subsamples = n_subsamples\n",
    "        self.max_depth = max_depth\n",
    "        self.tree_ = None\n",
    "\n",
    "    def _adaptive_subsample_frac(self, n_samples):\n",
    "        return min(0.7, max(0.3, 200 / n_samples))\n",
    "\n",
    "    def _best_stable_split_cv(self, X, y):\n",
    "        n_samples = len(X)\n",
    "        subsample_frac = self._adaptive_subsample_frac(n_samples)\n",
    "        n_sub = int(n_samples * subsample_frac)\n",
    "        split_scores = defaultdict(list)\n",
    "\n",
    "        for _ in range(self.n_subsamples):\n",
    "            idx_train = np.random.choice(n_samples, size=n_sub, replace=False)\n",
    "            idx_test = np.setdiff1d(np.arange(n_samples), idx_train)\n",
    "\n",
    "            X_train, y_train = X[idx_train], y[idx_train]\n",
    "            X_test, y_test = X[idx_test], y[idx_test]\n",
    "\n",
    "            if len(np.unique(y_train)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                continue\n",
    "\n",
    "            stump = clone(self.base_estimator)\n",
    "            stump.fit(X_train, y_train)\n",
    "\n",
    "            if stump.tree_.feature[0] < 0:\n",
    "                continue\n",
    "\n",
    "            feat = stump.tree_.feature[0]\n",
    "            thresh = stump.tree_.threshold[0]\n",
    "            preds = stump.predict(X_test)\n",
    "            loss = np.mean(preds != y_test)\n",
    "\n",
    "            split_scores[(feat, thresh)].append(loss)\n",
    "\n",
    "        if not split_scores:\n",
    "            return None\n",
    "\n",
    "        avg_scores = {split: np.mean(scores) for split, scores in split_scores.items()}\n",
    "        best_split = min(avg_scores.items(), key=lambda x: x[1])[0]\n",
    "        return best_split\n",
    "\n",
    "    def _grow_tree(self, X, y, depth):\n",
    "        if depth >= self.max_depth or len(set(y)) == 1:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "        split = self._best_stable_split_cv(X, y)\n",
    "        if split is None:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "        feat, thresh = split\n",
    "        left_idx = X[:, feat] <= thresh\n",
    "        right_idx = ~left_idx\n",
    "\n",
    "        if sum(left_idx) == 0 or sum(right_idx) == 0:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "        return {\n",
    "            'feature': feat,\n",
    "            'threshold': thresh,\n",
    "            'left': self._grow_tree(X[left_idx], y[left_idx], depth + 1),\n",
    "            'right': self._grow_tree(X[right_idx], y[right_idx], depth + 1)\n",
    "        }\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree_ = self._grow_tree(np.array(X), np.array(y), depth=0)\n",
    "\n",
    "    def _predict_one(self, x, node):\n",
    "        if not isinstance(node, dict):\n",
    "            return node\n",
    "        if x[node['feature']] <= node['threshold']:\n",
    "            return self._predict_one(x, node['left'])\n",
    "        else:\n",
    "            return self._predict_one(x, node['right'])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_one(x, self.tree_) for x in X])\n",
    "\n",
    "# Evaluation script\n",
    "def evaluate():\n",
    "    datasets = {\n",
    "        \"Low Noise\": make_classification(n_samples=1000, n_features=10, n_informative=7, n_redundant=2, flip_y=0.01, random_state=0),\n",
    "        \"Moderate Noise\": make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=2, flip_y=0.15, random_state=1),\n",
    "        \"Heavy Noise\": make_classification(n_samples=1000, n_features=10, n_informative=3, n_redundant=2, flip_y=0.3, random_state=2),\n",
    "        \"Very Heavy Noise\": make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=2, flip_y=0.45, random_state=4),\n",
    "        \"Breast Cancer\": load_breast_cancer(return_X_y=True),\n",
    "        \"Wine\": load_wine(return_X_y=True),\n",
    "        \"Digits\": load_digits(return_X_y=True),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for name, (X, y) in datasets.items():\n",
    "        X, y = shuffle(X, y, random_state=42)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        robust_cart = RobustCART(max_depth=5)\n",
    "        robust_cart.fit(X_train, y_train)\n",
    "        y_pred_robust = robust_cart.predict(X_test)\n",
    "\n",
    "        sklearn_cart = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "        sklearn_cart.fit(X_train, y_train)\n",
    "        y_pred_sklearn = sklearn_cart.predict(X_test)\n",
    "\n",
    "        results.append({\"Dataset\": name, \"Model\": \"Robust CART\", \"OOS Accuracy\": accuracy_score(y_test, y_pred_robust)})\n",
    "        results.append({\"Dataset\": name, \"Model\": \"Sklearn CART\", \"OOS Accuracy\": accuracy_score(y_test, y_pred_sklearn)})\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results_df = evaluate()\n",
    "    print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e45d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Data Science)",
   "language": "python",
   "name": "py311ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
